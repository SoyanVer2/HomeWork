{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78618462-b22e-4b87-be45-1166b3fd27dc",
   "metadata": {},
   "source": [
    "1. Дан датафрейм с категориальным столбцом Color. Необходимо преобразовать этот столбец в числовые значения с помощью `LabelEncoder`.\n",
    "\n",
    "P.S. Сам столбец Color можно удалить или оставить в датафрейме (на ваше усмотрение), в рамках задания - это не критично."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f75c850-db72-4092-a547-aef13b970b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red', 'Green']\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6d2a45-5e4f-4fc5-86a2-579ee1957fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>Color_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Color  Color_encoded\n",
       "0    Red              2\n",
       "1   Blue              0\n",
       "2  Green              1\n",
       "3   Blue              0\n",
       "4    Red              2\n",
       "5  Green              1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Инициализируем LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Преобразуем столбец 'Color'\n",
    "df['Color_encoded'] = label_encoder.fit_transform(df['Color'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94893fb-6d62-4f6a-99a6-78999f22ed7d",
   "metadata": {},
   "source": [
    "2. Используя тот же датафрейм, преобразуйте столбец Color в дамми-переменные с помощью `OneHotEncoder`.\n",
    "\n",
    "P.S. Сам столбец Color можно удалить или оставить в датафрейме (на ваше усмотрение), в рамках задания - это не критично."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4cff893-84a3-4e6a-8522-c30d07a256fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red', 'Green']\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b952da07-4a73-4318-aff6-0c8b4e4e4c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>Color_Blue</th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Green</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Color  Color_Blue  Color_Green  Color_Red\n",
       "0    Red         0.0          0.0        1.0\n",
       "1   Blue         1.0          0.0        0.0\n",
       "2  Green         0.0          1.0        0.0\n",
       "3   Blue         1.0          0.0        0.0\n",
       "4    Red         0.0          0.0        1.0\n",
       "5  Green         0.0          1.0        0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Инициализируем OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Преобразуем столбец 'Color'\n",
    "encoded_colors = one_hot_encoder.fit_transform(df[['Color']])\n",
    "\n",
    "# Создаем новый датафрейм с дамми-переменными\n",
    "encoded_df = pd.DataFrame(encoded_colors, columns=one_hot_encoder.get_feature_names_out(['Color']))\n",
    "\n",
    "# Объединяем с исходным датафреймом\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f975ac7c-4caf-4ff6-8682-8c7bba1060b3",
   "metadata": {},
   "source": [
    "3. Используя датафрейм:\n",
    "- создайте дамми-переменные для столбца Color с помощью `pandas.get_dummies` и выведи получившейся датафрейм\n",
    "- затем преобразуйте тип данных в int и также выведите результат получившегося датафрейма\n",
    "P.S. Сам столбец Color можно удалить или оставить в датафрейме (на ваше усмотрение), в рамках задания - это не критично."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25ec170a-3098-49d5-a145-a8103919dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red', 'Green']\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90bde280-43f2-4b7b-b40a-0a4465c9bf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>Color_Blue</th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Green</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Color  Color_Blue  Color_Green  Color_Red\n",
       "0    Red       False        False       True\n",
       "1   Blue        True        False      False\n",
       "2  Green       False         True      False\n",
       "3   Blue        True        False      False\n",
       "4    Red       False        False       True\n",
       "5  Green       False         True      False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем дамми-переменные с помощью pandas.get_dummies\n",
    "dummies = pd.get_dummies(df['Color'], prefix='Color')\n",
    "\n",
    "# Объединяем с исходным датафреймом\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca4bb2a1-aba4-4c13-90e8-3115c57771b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>Color_Blue</th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Green</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Color  Color_Blue  Color_Green  Color_Red\n",
       "0    Red           0            0          1\n",
       "1   Blue           1            0          0\n",
       "2  Green           0            1          0\n",
       "3   Blue           1            0          0\n",
       "4    Red           0            0          1\n",
       "5  Green           0            1          0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Color_Blue', 'Color_Green', 'Color_Red']] = df[['Color_Blue', 'Color_Green', 'Color_Red']].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f74fa44-ccaa-4588-b0e5-f37bc115fd16",
   "metadata": {},
   "source": [
    "4. Дан набор данных с признаками `Color` и `Size`, а также целевой переменной `Label`. Необходимо обработать категориальные признаки с помощью OneHotEncoder и обучить модель логистической регрессии для предсказания `Label`. Метрика качества - accuracy. \n",
    "\n",
    "P.S. Не гонитесь за улучшением метрики качества, в рамках задания этого не требуется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7025389-6a81-4fb2-899b-86e7f783cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Color': ['Red', 'Blue', 'Green', 'Blue', 'Red', 'Green'],\n",
    "    'Size': ['S', 'M', 'L', 'M', 'S', 'L'],\n",
    "    'Label': [1, 0, 1, 0, 1, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdc7a117-ce82-4b30-bf5e-72254d49f236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Разделяем признаки и целевую переменную\n",
    "X = df[['Color', 'Size']]\n",
    "y = df['Label']\n",
    "\n",
    "# Инициализируем OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # drop='first' для избежания дамми-переменных с мультиколлинеарностью\n",
    "\n",
    "# Преобразуем категориальные признаки\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Разделяем данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучаем модель логистической регрессии\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказываем на тестовой выборке\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оцениваем точность\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Точность модели: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c8720-845e-47b3-b748-03e7f693874a",
   "metadata": {},
   "source": [
    "5. Дан датафрейм с числовыми признаками `Height` и `Weight`. Необходимо стандартизировать эти признаки с помощью `StandardScaler`, чтобы они имели среднее значение 0 и стандартное отклонение 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd1536d2-2063-4f8e-96d9-949b881d5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Height': [150, 160, 170, 180, 190],\n",
    "    'Weight': [50, 60, 70, 80, 90]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05282020-504a-4400-84ec-59f2c6c0c6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.414214</td>\n",
       "      <td>-1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Height    Weight\n",
       "0 -1.414214 -1.414214\n",
       "1 -0.707107 -0.707107\n",
       "2  0.000000  0.000000\n",
       "3  0.707107  0.707107\n",
       "4  1.414214  1.414214"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Инициализируем StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Выбираем признаки для масштабирования\n",
    "features = ['Height', 'Weight']\n",
    "\n",
    "# Применяем масштабирование\n",
    "df_scaled = df.copy()\n",
    "df_scaled[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e08648-b070-44ef-b7d8-2737e959c412",
   "metadata": {},
   "source": [
    "6. Используйте набор данных Iris для построения модели логистической регрессии, которая классифицирует виды ириса по их признакам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2ccefa-ff14-4bbc-bd3d-e3b5b7ae9c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdbd7870-6cf8-42f3-9c26-99c1d9211701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание и обучение модели\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Точность модели: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff505a4-e53a-4152-a34e-f0ea25d5bd15",
   "metadata": {},
   "source": [
    "7. Дан датафрейм с числовыми признаками `Age` и `Income`. Необходимо масштабировать эти признаки с помощью `MinMaxScaler`, чтобы их значения находились в диапазоне от 0 до 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5144f929-eab4-42b1-89c2-787149b2d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Age': [25, 30, 35, 40, 45],\n",
    "    'Income': [50000, 60000, 70000, 80000, 90000]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dcd61d0-e5aa-420f-9a2b-b2f7903d83c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Income\n",
       "0  0.00    0.00\n",
       "1  0.25    0.25\n",
       "2  0.50    0.50\n",
       "3  0.75    0.75\n",
       "4  1.00    1.00"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Инициализируем MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Выбираем признаки для масштабирования\n",
    "features = ['Age', 'Income']\n",
    "\n",
    "# Применяем масштабирование\n",
    "df_scaled = df.copy()\n",
    "df_scaled[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1055b78-0f78-41be-98fd-52e44ae16ab0",
   "metadata": {},
   "source": [
    "8. Дан набор данных с категориальными признаками `Department` и `Education`, а также числовыми признаками `Experience` и `Salary`. Необходимо:\n",
    "\n",
    "- 1. Преобразовать категориальные признаки с помощью `OneHotEncoder`.\n",
    "- 2. Масштабировать числовые признаки с помощью `StandardScaler`.\n",
    "- 3. Объединить все признаки в один массив."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f84b91d-1ae4-4c95-8f33-35ff73ef6f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Department': ['Sales', 'Engineering', 'HR', 'Engineering', 'Sales', 'HR', 'Sales', 'Engineering', 'HR', 'Sales'],\n",
    "    'Education': ['Bachelor', 'Master', 'Bachelor', 'PhD', 'Master', 'Bachelor', 'PhD', 'Master', 'PhD', 'Bachelor'],\n",
    "    'Experience': [5, 7, 3, 10, 6, 4, 8, 9, 2, 7],\n",
    "    'Salary': [50000, 80000, 40000, 120000, 70000, 45000, 90000, 110000, 35000, 75000]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8793a8b8-8037-4276-b03c-4829e60a7263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        , -0.44574249, -0.77217826],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.3646984 ,  0.30527978],\n",
       "       [ 0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        , -1.25618339, -1.13133094],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  1.58035975,  1.7418905 ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "         0.        , -0.04052204, -0.0538729 ],\n",
       "       [ 0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        , -0.85096294, -0.9517546 ],\n",
       "       [ 0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.76991885,  0.66443246],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  1.1751393 ,  1.38273782],\n",
       "       [ 0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        , -1.66140384, -1.31090729],\n",
       "       [ 0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.3646984 ,  0.12570344]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Разделяем признаки и целевую переменную (в данном случае целевая переменная отсутствует)\n",
    "X = df[['Department', 'Education', 'Experience', 'Salary']]\n",
    "\n",
    "# Определяем категориальные и числовые признаки\n",
    "categorical_features = ['Department', 'Education']\n",
    "numeric_features = ['Experience', 'Salary']\n",
    "\n",
    "# Создаем ColumnTransformer для обработки различных типов признаков\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_features),\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ])\n",
    "\n",
    "# Создаем пайплайн (в данном случае только препроцессинг)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Применяем препроцессинг\n",
    "X_processed = pipeline.fit_transform(X)\n",
    "\n",
    "# Преобразованный массив\n",
    "X_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d5df6-b148-433f-94ae-e6a2bbd7fa66",
   "metadata": {},
   "source": [
    "**Задание со звездочкой***\n",
    "\n",
    "8. Вам предоставлен набор данных, содержащий информацию о сотрудниках компании. Ваша задача — обработать данные, подготовить их для обучения модели машинного обучения и обучить модель `логистической регрессии` для классификации сотрудников по уровню зарплаты (`High`, если зарплата > 70000 и Low в противном случае). После обучения модели необходимо оценить её производительность.\n",
    "\n",
    "Методы, которые нужно будет применить:\n",
    "- для категориальных фичей применить `OneHotEncoder`\n",
    "- для числовых фичей применить `StandardScaler`\n",
    "\n",
    "Для применения этих преобразований сразу, вам предлагается использовать `ColumnTransformer`, который позволяет одновременно применять различные преобразования к разным типам признаков.\n",
    "Также предлагается использовать метод `pipeline` для объединения этапов предобработки и обучения модели. Это обеспечит последовательное применение всех шагов.\n",
    "\n",
    "В качестве итога выведите `classification_report`\n",
    "\n",
    "Обратите внимание, что целевая переменная с необходимым условием (которое есть в начале задания) у вас уже прописана!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11943cf4-d60f-4879-9417-ce5623c17d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Увеличенный набор данных\n",
    "data = {\n",
    "    'Department': ['Sales', 'Engineering', 'HR', 'Engineering', 'Sales', 'HR', 'Sales', 'Engineering', 'HR', 'Sales'],\n",
    "    'Education': ['Bachelor', 'Master', 'Bachelor', 'PhD', 'Master', 'Bachelor', 'PhD', 'Master', 'PhD', 'Bachelor'],\n",
    "    'Experience': [5, 7, 3, 10, 6, 4, 8, 9, 2, 7],\n",
    "    'Salary': [50000, 80000, 40000, 120000, 70000, 45000, 90000, 110000, 35000, 75000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --Целевая переменная--\n",
    "df['Salary_Class'] = df['Salary'].apply(lambda x: 'Low' if x <= 70000 else 'High')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "270a5d92-0b20-4697-adf8-e1a99b0ea584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Отчет о классификации на тестовой выборке:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      1.00      1.00         1\n",
      "         Low       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         2\n",
      "   macro avg       1.00      1.00      1.00         2\n",
      "weighted avg       1.00      1.00      1.00         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Разделяем признаки и целевую переменную\n",
    "X = df[['Department', 'Education', 'Experience', 'Salary']]\n",
    "y = df['Salary_Class']\n",
    "\n",
    "# Определяем категориальные и числовые признаки\n",
    "categorical_features = ['Department', 'Education']\n",
    "numeric_features = ['Experience', 'Salary']\n",
    "\n",
    "# Создаем ColumnTransformer для обработки различных типов признаков\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features),  # drop='first' для избежания дамми-ловушки\n",
    "        ('num', StandardScaler(), numeric_features)\n",
    "    ])\n",
    "\n",
    "# Создаем пайплайн с препроцессингом и моделью\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Разделяем данные на обучающую и тестовую выборки с сохранением пропорций классов\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Обучаем модель\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказываем на тестовой выборке\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Оцениваем модель\n",
    "print(\"\\nОтчет о классификации на тестовой выборке:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343900b-7a6a-471d-a3ec-1ad36102e889",
   "metadata": {},
   "source": [
    "9. Постройте модель K-ближайших соседей для классификации видов ириса и оцените её точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9810e7eb-7bd0-4405-976a-6488684b22de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a1efa37-fda7-4e1f-ac86-3bd5b92d9fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели KNN: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание и обучение модели KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Точность модели KNN: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4e39c-ffa4-47a2-9479-62573c1f64db",
   "metadata": {},
   "source": [
    "10. Постройте модель дерева решений для классификации видов ириса и оцените её точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbf53359-77a7-418c-a7b6-7b7ab8d80e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b16cd620-12d9-48f6-924f-17b92a18499a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели дерева решений: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание и обучение модели дерева решений\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Точность модели дерева решений: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4481a5-f519-4c61-9a03-8004a272a8f6",
   "metadata": {},
   "source": [
    "11. Постройте модель SVM для классификации видов ириса и оцените её точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8885740-3645-4641-a3c2-e19add397abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36ef4227-d65e-4981-a652-36b53e8d44e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели SVM: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание и обучение модели SVM\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Точность модели SVM: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d7321-c1e3-4695-9d4e-7a388c07e0c3",
   "metadata": {},
   "source": [
    "12. Постройте модель случайного леса для классификации видов ириса и оцените её точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d6f01d8-31ca-4893-9733-219842e8c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12a3a2b3-4634-4f5b-ad9f-399c373f78ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели случайного леса: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание и обучение модели случайного леса\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Точность модели случайного леса: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b7b542-f61e-4ede-bc8b-e7f8de8f574c",
   "metadata": {},
   "source": [
    "13. Используйте набор данных Iris для построения модели логистической регрессии. Выполните подбор гиперпараметров с помощью GridSearchCV для оптимизации параметра регуляризации C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ae02ab5-c23a-4d34-852d-bb073d355868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afef45aa-50ce-4943-8920-c23b2f793e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'C': 1}\n",
      "Точность модели: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение модели логистической регрессии\n",
    "log_reg = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Определение сетки гиперпараметров\n",
    "param_grid = {'C': [0.1, 1, 10, 100]}\n",
    "\n",
    "# Создание GridSearchCV\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Обучение модели\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(f'Лучшие параметры: {grid_search.best_params_}')\n",
    "\n",
    "# Предсказание на тестовой выборке\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Точность модели: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d9687c-7c2b-4d2e-8a99-e30b2f5e0f19",
   "metadata": {},
   "source": [
    "14. Используйте набор данных Breast Cancer Wisconsin для построения модели SVM. Выполните подбор гиперпараметров с помощью GridSearchCV для оптимизации параметров C и gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65415cc8-786f-48b1-b32d-304438300b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24e14777-9c15-4f1d-8781-6f0906ef9365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'C': 10, 'gamma': 0.0001}\n",
      "Точность модели SVM: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение модели SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Определение сетки гиперпараметров\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "# Создание GridSearchCV\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Обучение модели\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(f'Лучшие параметры: {grid_search.best_params_}')\n",
    "\n",
    "# Предсказание на тестовой выборке\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Точность модели SVM: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbe72a-47d8-4239-9003-d470fbf8fd5d",
   "metadata": {},
   "source": [
    "15. Используйте набор данных Wine для построения модели случайного леса. Выполните подбор гиперпараметров с помощью RandomizedSearchCV для оптимизации параметров n_estimators и max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8b4d75-ce44-4341-bb85-20e0d6842bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Загрузка данных\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd6e065-abd0-4db5-b224-65a497785127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'max_depth': 12, 'n_estimators': 70}\n",
      "Точность модели случайного леса: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение модели случайного леса\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Определение распределений гиперпараметров\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),\n",
    "    'max_depth': randint(5, 20)\n",
    "}\n",
    "\n",
    "# Создание RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=20, cv=5, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Обучение модели\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(f'Лучшие параметры: {random_search.best_params_}')\n",
    "\n",
    "# Предсказание на тестовой выборке\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Точность модели случайного леса: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f5fc1-d9f2-4fa3-8fe3-839a9f233f3e",
   "metadata": {},
   "source": [
    "16. Используйте набор данных Digits для построения модели градиентного бустинга. Выполните подбор гиперпараметров с помощью GridSearchCV для оптимизации параметров n_estimators и learning_rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea29a87-6a7e-4908-8952-e04a2d112cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Загрузка данных\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2daf61c4-5c98-4728-871c-f96e2bc9c76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Точность модели градиентного бустинга: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определение модели градиентного бустинга\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Определение сетки гиперпараметров\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Создание GridSearchCV\n",
    "grid_search = GridSearchCV(gb, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Обучение модели\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Лучшие параметры\n",
    "print(f'Лучшие параметры: {grid_search.best_params_}')\n",
    "\n",
    "# Предсказание на тестовой выборке\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Точность модели градиентного бустинга: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2840a75f-9a1a-4ab5-a929-a7bd2d40703a",
   "metadata": {},
   "source": [
    "17. Используйте набор данных Iris для построения модели логистической регрессии. Примените метод кросс-валидации K-Fold с 5 фолдами для оценки точности модели.\n",
    "P.S. Перебор гипперпараметров делать не надо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b32ad2c-9319-42fd-a27a-17028f8d3b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Загрузка данных\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e908b6cf-784b-488d-afb1-244a8d695d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точности по фолдам: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "Средняя точность: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Определение модели логистической регрессии\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Применение кросс-валидации K-Fold с 5 фолдами\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Вывод результатов\n",
    "print(f'Точности по фолдам: {scores}')\n",
    "print(f'Средняя точность: {scores.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b4e52-abff-409d-a6c0-e88c8b076d5f",
   "metadata": {},
   "source": [
    "18. Используйте набор данных Breast Cancer Wisconsin для построения модели дерева решений. Примените стратифицированную кросс-валидацию (StratifiedKFold) с 5 фолдами для оценки точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db7072fa-3cb0-4fa8-ab78-4c36da7213b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Загрузка данных\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b8df758-132f-4842-a9ee-594c84827e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точности по фолдам: [0.92105263 0.89473684 0.92982456 0.92982456 0.92920354]\n",
      "Средняя точность: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Определение модели дерева решений\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Определение стратифицированной кросс-валидации с 5 фолдами\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Применение кросс-валидации\n",
    "scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Вывод результатов\n",
    "print(f'Точности по фолдам: {scores}')\n",
    "print(f'Средняя точность: {scores.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0cd25d-9277-46cc-b8ee-5f8a4101b1c2",
   "metadata": {},
   "source": [
    "19. Используйте набор данных Digits для построения модели K-ближайших соседей (KNN). Примените метод кросс-валидации Leave-One-Out (LOOCV) для оценки точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d53a7798-5735-44fe-9260-b7844fbb91da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "\n",
    "# Загрузка данных\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "639d83dc-54ce-44b0-ae33-3e6bfc2a102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя точность (LOOCV): 0.99\n"
     ]
    }
   ],
   "source": [
    "# Определение модели KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Определение Leave-One-Out кросс-валидации\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Применение кросс-валидации\n",
    "scores = cross_val_score(knn, X, y, cv=loo, scoring='accuracy')\n",
    "\n",
    "# Вывод результатов\n",
    "print(f'Средняя точность (LOOCV): {scores.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be485e7-1850-49e5-8b73-e1fa908892d9",
   "metadata": {},
   "source": [
    "20. Используйте набор данных Wine для построения модели случайного леса. Примените метод кросс-валидации StratifiedKFold с 3 фолдами, учитывая, что каждый фолд соответствует определённой группе (например, сорт вина)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91df4932-7b4c-4975-8813-dba6661ea83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка данных\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b74a8f-40a2-481e-b1d4-c996ef34eede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точности по фолдам: [0.98333333 1.         0.98305085]\n",
      "Средняя точность: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Определение модели случайного леса\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Определение StratifiedKFold с 3 фолдами\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Применение кросс-валидации\n",
    "scores = cross_val_score(rf, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Вывод результатов\n",
    "print(f'Точности по фолдам: {scores}')\n",
    "print(f'Средняя точность: {scores.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa4c0c-fff2-44b7-b4c1-ac1a978a776c",
   "metadata": {},
   "source": [
    "21. Используйте набор данных Breast Cancer Wisconsin для построения модели градиентного бустинга. Примените метод кросс-валидации ShuffleSplit с 5 итерациями и размером тестовой выборки 20% для оценки точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89854e69-4ec3-49a9-85e6-4c259001803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "\n",
    "# Загрузка данных\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8234cacb-9d56-4578-a71b-43c238678442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точности по фолдам: [0.95614035 0.96491228 0.96491228 0.97368421 0.96491228]\n",
      "Средняя точность: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Определение модели градиентного бустинга\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Определение ShuffleSplit кросс-валидации\n",
    "shuffle_split = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение кросс-валидации\n",
    "scores = cross_val_score(gb, X, y, cv=shuffle_split, scoring='accuracy')\n",
    "\n",
    "# Вывод результатов\n",
    "print(f'Точности по фолдам: {scores}')\n",
    "print(f'Средняя точность: {scores.mean():.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
